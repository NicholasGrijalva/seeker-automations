"""
Audio Transcription Module

Converts voice memos to text using OpenAI Whisper (API or local).
"""

import logging
from pathlib import Path
from typing import Optional

from openai import OpenAI

from config.settings import settings

logger = logging.getLogger(__name__)


class Transcriber:
    """Transcribe audio files to text using Whisper."""

    SUPPORTED_FORMATS = {".m4a", ".mp3", ".mp4", ".wav", ".webm", ".mpeg", ".mpga", ".ogg"}

    def __init__(self):
        self.mode = settings.whisper_mode
        self.model = settings.whisper_model

        if self.mode == "api":
            self.client = OpenAI(api_key=settings.openai_api_key)
        else:
            # Local whisper - lazy import to avoid loading if not needed
            self._local_model = None

    def _get_local_model(self):
        """Lazy load local whisper model."""
        if self._local_model is None:
            import whisper
            logger.info(f"Loading local Whisper model: {self.model}")
            self._local_model = whisper.load_model(self.model)
        return self._local_model

    def transcribe(self, audio_path: str | Path) -> dict:
        """
        Transcribe an audio file to text.

        Args:
            audio_path: Path to the audio file

        Returns:
            dict with keys:
                - text: Full transcript text
                - segments: List of timestamped segments (if available)
                - duration: Audio duration in seconds (if available)
                - language: Detected language
        """
        audio_path = Path(audio_path)

        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")

        if audio_path.suffix.lower() not in self.SUPPORTED_FORMATS:
            raise ValueError(f"Unsupported audio format: {audio_path.suffix}")

        logger.info(f"Transcribing: {audio_path.name} (mode={self.mode})")

        if self.mode == "api":
            return self._transcribe_api(audio_path)
        else:
            return self._transcribe_local(audio_path)

    def _transcribe_api(self, audio_path: Path) -> dict:
        """Transcribe using OpenAI Whisper API."""
        with open(audio_path, "rb") as audio_file:
            response = self.client.audio.transcriptions.create(
                model=self.model,
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )

        return {
            "text": response.text,
            "segments": [
                {
                    "start": seg.start,
                    "end": seg.end,
                    "text": seg.text
                }
                for seg in (response.segments or [])
            ],
            "duration": response.duration,
            "language": response.language
        }

    def _transcribe_local(self, audio_path: Path) -> dict:
        """Transcribe using local Whisper model."""
        model = self._get_local_model()
        result = model.transcribe(str(audio_path))

        return {
            "text": result["text"],
            "segments": [
                {
                    "start": seg["start"],
                    "end": seg["end"],
                    "text": seg["text"]
                }
                for seg in result.get("segments", [])
            ],
            "duration": result.get("segments", [{}])[-1].get("end") if result.get("segments") else None,
            "language": result.get("language")
        }

    def transcribe_with_summary(self, audio_path: str | Path) -> dict:
        """
        Transcribe and generate a brief summary title.

        Returns dict with additional 'title' key.
        """
        result = self.transcribe(audio_path)

        # Generate a title from first ~100 words
        words = result["text"].split()[:100]
        preview = " ".join(words)

        # Title will be generated by classifier, but we can provide a fallback
        if len(result["text"]) < 50:
            result["title"] = result["text"]
        else:
            result["title"] = preview[:100] + "..."

        return result


# Convenience function
def transcribe_audio(audio_path: str | Path) -> dict:
    """Quick transcription function."""
    transcriber = Transcriber()
    return transcriber.transcribe(audio_path)
